# 01. Introduction to Human-Computer Interaction

Andy Cockburn: Room 313, working Thursdays and Fridays

Tutors: `team368@cosc.canterbury.ac.nz`

Course breakdown:

- Labs: 9%, 1% per lab
- Usability analysis and storyboard
  - 25%, 5pm 22 September
- Design specification and rationale
  - 15%, 5pm 20 October
- Exam: 51%

Goals:

- Understand key human factors influencing HCI
- Know and apply guidelines, models, methods that aid in interface design

HCI: discipline concerned with the design, evaluation and implementation of interactive computing systems for human use.

There should be a cycle of evaluating, designing and implementation.

## Usability

Three key pillars:

- Learnability: rapid attainment of some level of performance
  - Can be modelled as the inverse of time spent on the interface
- Efficiency: can get a lot of work done per unit time
- Subjective satisfaction: how much you enjoy using it

Two minor pillars:

- Errors: should be few errors in an efficient interface.
- Memorability: should be memorable if the interface is learnable.

Trade-offs: efficiency and learnability (inverse of time spent) are often at odds with each other. The performance/efficiency ceiling is often lower for more learnable interfaces.

### Preliminary Factors

- Safety considerations
- Need for throughput (efficiency)
- Frequency of use
- Physical space, lighting, noise, pollution
- Social context
- Cognitive factors: age, fatigue, stress, focus

Usability is like oxygen: you only notice it when it's absent. See: doors with handles that you need to push.

### Managing Complexity

The job of HCI is to manage complexity: designing an object to be simple and clear; **the relentless pursuit of simplicity**.


```
Interface
Complexity
    ^
    |                                              ____
    |                                         ____/
    | Poorly designed                    ____/
    | UIs; complexity               ____/
    | amplified                ____/
    |                     ____/     Well designed UIs
    |                ____/
    |           ____/
    |      ____/
    | ____/
    |/
    ---------------------------------------------------> Domain
     Door      Word        CAD          Nuclear          Complexity
             Processor                power plant
```

### Models

Models are **simplifications of reality** that (should) help with the understanding of a complex artifact.

#### Don Norman's Model of Interaction

From 'The Psychology/Design of Everyday Things', 1988.

This helps understand the designer's role in creating a system that is used by a thinking person.

```
               constructs
   Designer/ -------------> System/system image
designer model                ^
                    Provides  | Provides input based on
                    feedback/ | their prediction of how
                     output   |  to achieve their goal 
                              v
                             User/
                          user model
```

The designer tries to construct a system that they have **not fully defined**. The *designer's model* is their *conception of interaction*; often incomplete, fuzzy or compromised in the actual implementation.

System image: the way the system *appears* to the user; this does not necessarily reflect the truth of the system.

<!-- System image: sum of all information (previous experience, advertisements, manuals etc.) available about the system. The information may be wrong/incomplete. -->

The *user model* begins very weak, coming from familiarity with the real world or other similar systems. They will use this experience to try and interact with the user system, building their model based on *feedback* from the system.

Ideally, there should be conformance between the system image and user model.

There is no direct communication between the designer and user; the designer can only communicate with the user through the system.

##### Execute-Evaluate Cycle

Execute:

- Goal -> Intention -> Actions -> Execution
  - The user has a *goal* and know the outcome they want
  - They form an *intention* translate this to the language of the user interface; an *action*
  - 'Gulf of Execution': problems executing intentions/actions
- Evaluate
  - Perceive -> Interpret -> Evaluate
    - *Perceive* the response/feedback by the system to their actions
    - *Evaluate*; determine the effect of their action. Did it meet their goal?
    - 'Gulf of Evaluation': problems assessing state, determining effect etc.

#### UISO Interaction and Framework

Emphasizes translation during interaction

Articulation: user's task language to input language
Performance: callbacks etc.
Presentation: show new state
Observation: interpretation

User has some low level task (e.g. saving a file); they need to translate their intention to an input language; this is one of the most difficult parts of user interface design.

```
              --> Output ---
Presentation /              \ Observation
            /                \
           /                  v
    System                      User
    (Core)                      (Task)
           ^                  /
Performance \                / Articulation
             \--- Input <---/
```

### Mappings

Good mappings between user and input/output increase usability.

#### Affordances

Objects afford particular actions to users:

- Door handles afford pulling
- Dials afford turning
- Buttons afford pushing
- Bush shelters
  - Glass affords smashing
  - Plywood affords graffiti

Poor affordances encourages incorrect actions, but strong affordances may stifle efficiency.

#### Over-/Under-determined Dialogues

- Well-determined: natural translation from task to input language
- Under-determined: user knows what they want to do but not how to do it
  - e.g. command line
- Over-determined: user forced through unnecessary or unnatural steps
  - e.g. 'Click OK to proceed', lengthy wizards
  - User turns into a robot; no freedom in what to do

Beginner user interface designers tend to think about the interface in terms of system requirements: the system needs x, y, z information so lets ask the user about these things up-front. These over-determined dialogues lead to horrible design.

#### Direct Manipulation

- Visibility of objects
- Direct, rapid, incremental and **reversible** actions:
- Reversibility allows users **no-risk exploration of the user interface**
- Rapid feedback
- Syntactic correctness
  - Disable illegal actions (e.g. greying buttons out when action not available)
    - Tooltips can help with the problem of not knowing why the action is not available
- Replace language with action
  - Language needs to be learned and remembered (e.g. command lines)
  - Actions; see and point

Advantages:

- Easy to learn
- Low memory requirements
- Easy to undo
- Immediate feedback to user actions
- Users can use spatial cues

Disadvantages:

- Consumes more screen real estate
- High graphical system requirements
- May trap users in 'beginner mode'

## The Human

- Input: vision, hearing, haptics
- Output: pointing, steering, speech, typing etc.
- Processing: visual search (slow), decision times (fast), learning
- Memory
- Phenomena and collaboration
- Error (predictably irrational behaviour)

### Fun Example

A trivial task that many humans will get wrong.

Count the number of occurrences of the letter 'f' given a set of words:

> Finished files are the results of years of scientific study combined with the experience of many years

Three phonetics Fs: 'finished', 'files', 'scientific', are easily found.

But three non-phonetic Fs in 'of' are often forgotten.

### [Click](http://blogoscoped.com/click2/)

Even a blank graphic has affordances on where people usually click: on or near the center, or along the diagonals or corners.

### Human Factors

Psychological and physiological abilities hae implications for design:

- Perception: how we perceive things
- Cognitive: how we process information
- Motor: how we perform actions
- Social: how we interact with others

### The Human Information Processor

Card, Moran, Newell 1983.

<!-- GOMS:

- Goal
- Operators: ways to go about executing the task
- Methods: alternate methods to execute
- Selectors: selecting methods

Sub-divide into low-level (keystrokes) tasks.

KLM:

-  -->

```
               Eyes/Ears
                   │
                   ▼
    ┌──── Perceptual Processor ────┐
    │                              │
    ▼                              ▼
Visual Image ──────┬─────── Auditory Image
 Storage           │           Storage
                   │
                   ▼
      ┌─────Working Memory ◄─────────┐
      ▼                  ▲           ▼
    Motor                │        Long-Term
  Processor              │         Memory
      │                  │           ▲
      |                  |           |
      ▼                  │           ▼
  Movement               └──────► Cognitive
  Response                        Processor 
```

### Human Input

#### Vision

Cells:

- Rods: low light, monochrome, 100 million rods across the retina
- Cones: color, 6 million rods in fovea
  - S/M/L for short/medium/long approx blue/green/reddish-yellow sensitivity

Areas:

- Retina: ~120 degree range, sensitive to movement
  - ~210 degrees with both eyes
  - Notifications popping up in corners etc. will distract user
- Fovea: detailed vision, area of ~2 degrees

1 degree = 60 arcminutes, 1 arcminute = 60 arcseconds

Visual Acuity:

- Point acuity; maximum angle between two dots before they become indistinct: 1 arcminute
- Grating acuity; maximum angle between alternating bars before they become indistinct: 1-2 arcminutes
- Letter acuity: 5 minutes of arc
- Vernier acuity: given two parallel lines, minimum angle of separation in normal axis (e.g. `---___`) before they are perceived as a continuous line (colinear): 10 arcseconds

Eye movement:

- Fixations: visual processing occurs only when the eye is stationary
- Saccades: rapid eye movements; about 900 degrees per second
  - Blind while saccades are in progress
- Eye movement as input; difficult as people don't have much control over where they are looking (e.g. accidentally looking at 'delete all my files' button)
- Smooth-pursuit: ability to tracking moving objects (up to 100 degrees per second)
  - **Cannot be induced voluntarily** - can't imagine a moving dot and track it
  - Relevant in scrolling

Size/depth cues:

- Familiarity
- Linear perspective; straight lines getting closer together
- Horizontal distance
- Size constancy: if object gets bigger/smaller, it's probably the object moving closer/further away, not the object changing size
- Texture gradient: texture getting bigger/smaller
- Occlusion: occluded items further away
- Depth of focus: blurrier the further you go away
- Aerial perspective: blurrier and bluer from atmospheric haze
- Shadows/shading
- Stereoscopy (best within 1m, ineffective beyond 10m)
